/proj/synthetic_alzheimer/users/x_almle/mri-sr-bob
***********************************
You have loaded a Miniforge3 module
***********************************
---------------------------------------------------------------------------------------------------
NOTE: NSC strongly advices against placing 'mamba activate' (or 'conda
activate', with or without
      arguments) or conda initialize commands in your shell initialization
files, (e.g. '.bashrc' or '.bash_profile') since
      this severely alters the environment for running software in ways that
cause unpredictable
      issues that can be difficult to diagnose.
---------------------------------------------------------------------------------------------------

hey
Start at: 2025-10-08T10:11:37.521130
T1 files: 71, T2 files: 71, T2 LR files: 71
71
Train patches: 49, Val patches: 11, Test patches: 11
Number of training batches: 38539
Network initialized
Number of epochs: 100
Using: cuda (SLURM GPUs: 1)
Starting training...
Epoch 1/100, Loss: 0.0039
Epoch 2/100, Loss: 0.0012
Epoch 3/100, Loss: 0.0010
Epoch 4/100, Loss: 0.0009
Epoch 5/100, Loss: 0.0008
Epoch 6/100, Loss: 0.0007
Epoch 7/100, Loss: 0.0007
Epoch 8/100, Loss: 0.0007
Epoch 9/100, Loss: 0.0006
Epoch 10/100, Loss: 0.0006
Epoch 11/100, Loss: 0.0006
Epoch 12/100, Loss: 0.0006
Epoch 13/100, Loss: 0.0006
Epoch 14/100, Loss: 0.0005
Epoch 15/100, Loss: 0.0005
Epoch 16/100, Loss: 0.0005
Epoch 17/100, Loss: 0.0005
Epoch 18/100, Loss: 0.0005
Epoch 19/100, Loss: 0.0005
Epoch 20/100, Loss: 0.0005
Epoch 21/100, Loss: 0.0005
Epoch 22/100, Loss: 0.0005
Epoch 23/100, Loss: 0.0005
Epoch 24/100, Loss: 0.0005
Epoch 25/100, Loss: 0.0005
Epoch 26/100, Loss: 0.0005
Epoch 27/100, Loss: 0.0005
Epoch 28/100, Loss: 0.0005
Epoch 29/100, Loss: 0.0005
Epoch 30/100, Loss: 0.0005
Epoch 31/100, Loss: 0.0004
Epoch 32/100, Loss: 0.0004
Epoch 33/100, Loss: 0.0004
Epoch 34/100, Loss: 0.0004
Epoch 35/100, Loss: 0.0004
Epoch 36/100, Loss: 0.0004
Epoch 37/100, Loss: 0.0004
Epoch 38/100, Loss: 0.0004
Epoch 39/100, Loss: 0.0004
Epoch 40/100, Loss: 0.0004
Epoch 41/100, Loss: 0.0004
Epoch 42/100, Loss: 0.0004
Epoch 43/100, Loss: 0.0004
Epoch 44/100, Loss: 0.0004
Epoch 45/100, Loss: 0.0004
Epoch 46/100, Loss: 0.0004
Epoch 47/100, Loss: 0.0004
Epoch 48/100, Loss: 0.0004
Epoch 49/100, Loss: 0.0004
Epoch 50/100, Loss: 0.0004
Epoch 51/100, Loss: 0.0004
Epoch 52/100, Loss: 0.0004
Epoch 53/100, Loss: 0.0004
Epoch 54/100, Loss: 0.0004
Epoch 55/100, Loss: 0.0004
Epoch 56/100, Loss: 0.0004
Epoch 57/100, Loss: 0.0004
Epoch 58/100, Loss: 0.0004
Epoch 59/100, Loss: 0.0004
Epoch 60/100, Loss: 0.0004
Epoch 61/100, Loss: 0.0004
Epoch 62/100, Loss: 0.0004
Epoch 63/100, Loss: 0.0004
Epoch 64/100, Loss: 0.0004
Epoch 65/100, Loss: 0.0004
Epoch 66/100, Loss: 0.0004
Epoch 67/100, Loss: 0.0004
Epoch 68/100, Loss: 0.0004
Epoch 69/100, Loss: 0.0004
Epoch 70/100, Loss: 0.0004
Epoch 71/100, Loss: 0.0004
Epoch 72/100, Loss: 0.0004
Epoch 73/100, Loss: 0.0004
Epoch 74/100, Loss: 0.0004
Epoch 75/100, Loss: 0.0004
Epoch 76/100, Loss: 0.0004
Epoch 77/100, Loss: 0.0004
Epoch 78/100, Loss: 0.0004
Epoch 79/100, Loss: 0.0004
Epoch 80/100, Loss: 0.0004
Epoch 81/100, Loss: 0.0004
Epoch 82/100, Loss: 0.0004
Epoch 83/100, Loss: 0.0004
Epoch 84/100, Loss: 0.0004
Epoch 85/100, Loss: 0.0004
Epoch 86/100, Loss: 0.0004
Epoch 87/100, Loss: 0.0004
Epoch 88/100, Loss: 0.0004
Epoch 89/100, Loss: 0.0004
Epoch 90/100, Loss: 0.0004
Epoch 91/100, Loss: 0.0004
Epoch 92/100, Loss: 0.0004
Epoch 93/100, Loss: 0.0004
Epoch 94/100, Loss: 0.0004
Epoch 95/100, Loss: 0.0004
Epoch 96/100, Loss: 0.0004
Epoch 97/100, Loss: 0.0004
Epoch 98/100, Loss: 0.0004
Epoch 99/100, Loss: 0.0004
Epoch 100/100, Loss: 0.0004
Processed validation image 1/11
Processed validation image 2/11
Processed validation image 3/11
Processed validation image 4/11
Processed validation image 5/11
Processed validation image 6/11
Processed validation image 7/11
Processed validation image 8/11
Processed validation image 9/11
Processed validation image 10/11
Processed validation image 11/11
End at: 2025-10-08T19:11:36.794976
